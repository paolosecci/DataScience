{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter keys\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#authenticate tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news outlets for analysis\n",
    "news_outlets = []\n",
    "\n",
    "#append twitter handles of bbc, cbs, cnn, fox, nyt\n",
    "news_outlets.append('@BBCNews')\n",
    "news_outlets.append('@CBSNews')\n",
    "news_outlets.append('@CNN')\n",
    "news_outlets.append('@FoxNews')\n",
    "news_outlets.append('@NYTimes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists for each outlet\n",
    "bbc = [[],[],[],[]]\n",
    "cbs = [[],[],[],[]]\n",
    "cnn = [[],[],[],[]]\n",
    "fox = [[],[],[],[]]\n",
    "nyt = [[],[],[],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "###BBC\n",
    "\n",
    "#get 100 most recent tweets\n",
    "public_tweets = api.search(outlet, count=100, result_type=\"recent\")\n",
    "    \n",
    "#loop thru each tweet\n",
    "for tweet in public_tweets['statuses']:\n",
    "        \n",
    "    #run vader analysis\n",
    "    compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "    pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "    neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "    neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "        \n",
    "    #add results to matrix\n",
    "    bbc[0].append(compound)\n",
    "    bbc[1].append(pos)\n",
    "    bbc[2].append(neg)\n",
    "    bbc[3].append(neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "###CBS\n",
    "\n",
    "#get 100 most recent tweets\n",
    "public_tweets = api.search(outlet, count=100, result_type=\"recent\")\n",
    "    \n",
    "#loop thru each tweet\n",
    "for tweet in public_tweets['statuses']:\n",
    "        \n",
    "    #run vader analysis\n",
    "    compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "    pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "    neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "    neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "        \n",
    "    #add results to matrix\n",
    "    cbs[0].append(compound)\n",
    "    cbs[1].append(pos)\n",
    "    cbs[2].append(neg)\n",
    "    cbs[3].append(neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "###CNN\n",
    "\n",
    "#get 100 most recent tweets\n",
    "public_tweets = api.search(outlet, count=100, result_type=\"recent\")\n",
    "    \n",
    "#loop thru each tweet\n",
    "for tweet in public_tweets['statuses']:\n",
    "        \n",
    "    #run vader analysis\n",
    "    compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "    pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "    neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "    neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "        \n",
    "    #add results to matrix\n",
    "    cnn[0].append(compound)\n",
    "    cnn[1].append(pos)\n",
    "    cnn[2].append(neg)\n",
    "    cnn[3].append(neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "###FOX\n",
    "\n",
    "#get 100 most recent tweets\n",
    "public_tweets = api.search(outlet, count=100, result_type=\"recent\")\n",
    "    \n",
    "#loop thru each tweet\n",
    "for tweet in public_tweets['statuses']:\n",
    "        \n",
    "    #run vader analysis\n",
    "    compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "    pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "    neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "    neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "        \n",
    "    #add results to matrix\n",
    "    fox[0].append(compound)\n",
    "    fox[1].append(pos)\n",
    "    fox[2].append(neg)\n",
    "    fox[3].append(neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "###NYT\n",
    "\n",
    "#get 100 most recent tweets\n",
    "public_tweets = api.search(outlet, count=100, result_type=\"recent\")\n",
    "    \n",
    "#loop thru each tweet\n",
    "for tweet in public_tweets['statuses']:\n",
    "        \n",
    "    #run vader analysis\n",
    "    compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "    pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "    neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "    neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "        \n",
    "    #add results to matrix\n",
    "    nyt[0].append(compound)\n",
    "    nyt[1].append(pos)\n",
    "    nyt[2].append(neg)\n",
    "    nyt[3].append(neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store avg sentiment for each\n",
    "\n",
    "bbc_senti = {\"Compound\": np.mean(bbc[0]),\n",
    "             \"Positive\": np.mean(bbc[1]),\n",
    "             \"Neutral\": np.mean(bbc[2]),\n",
    "             \"Negative\": np.mean(bbc[3])}\n",
    "\n",
    "cbs_senti = {\"Compound\": np.mean(cbs[0]),\n",
    "             \"Positive\": np.mean(cbs[1]),\n",
    "             \"Neutral\": np.mean(cbs[2]),\n",
    "             \"Negative\": np.mean(cbs[3])}\n",
    "\n",
    "cnn_senti = {\"Compound\": np.mean(cnn[0]),\n",
    "             \"Positive\": np.mean(cnn[1]),\n",
    "             \"Neutral\": np.mean(cnn[2]),\n",
    "             \"Negative\": np.mean(cnn[3])}\n",
    "\n",
    "fox_senti = {\"Compound\": np.mean(fox[0]),\n",
    "             \"Positive\": np.mean(fox[1]),\n",
    "             \"Neutral\": np.mean(fox[2]),\n",
    "             \"Negative\": np.mean(fox[3])}\n",
    "\n",
    "nyt_senti = {\"Compound\": np.mean(nyt[0]),\n",
    "             \"Positive\": np.mean(nyt[1]),\n",
    "             \"Neutral\": np.mean(nyt[2]),\n",
    "             \"Negative\": np.mean(nyt[3])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Compound': -0.11995800000000002, 'Positive': 0.08449, 'Neutral': 0.11001000000000001, 'Negative': 0.8055099999999998}\n",
      "------------------------\n",
      "{'Compound': -0.14007300000000003, 'Positive': 0.08415999999999998, 'Neutral': 0.11478999999999999, 'Negative': 0.80106}\n",
      "------------------------\n",
      "{'Compound': -0.14007300000000003, 'Positive': 0.08415999999999998, 'Neutral': 0.11478999999999999, 'Negative': 0.80106}\n",
      "------------------------\n",
      "{'Compound': -0.14007300000000003, 'Positive': 0.08415999999999998, 'Neutral': 0.11478999999999999, 'Negative': 0.80106}\n",
      "------------------------\n",
      "{'Compound': -0.14316700000000002, 'Positive': 0.08283999999999998, 'Neutral': 0.11433, 'Negative': 0.8028400000000002}\n",
      "------------------------\n",
      "fin\n"
     ]
    }
   ],
   "source": [
    "print(bbc_senti)\n",
    "print('------------------------')\n",
    "print(cbs_senti)\n",
    "print('------------------------')\n",
    "print(cnn_senti)\n",
    "print('------------------------')\n",
    "print(fox_senti)\n",
    "print('------------------------')\n",
    "print(nyt_senti)\n",
    "print('------------------------')\n",
    "print('fin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
